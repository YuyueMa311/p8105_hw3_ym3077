---
title: "p8105_hw3_ym3077"
output: github_document
---

Load packages
```{r}
library(tidyverse)
library(lubridate)
```

## Problem 1

```{r}
library(p8105.datasets)
data("instacart")

instacart_summary = list(instacart)
head(instacart,10)
```
This `instacart` dataset has `r nrow(instacart)` observations for 131,209 users and `r ncol(instacart)` variables/rows, where each row represents a product from a single order and is associated with a customer.    
The 15 variables in this dataset are: `order_id` (order identifier), `product_id` (product identifier), `add_to_cart_order` (order of each product was added to cart), `reordered` (1 if ordered before, 0 otherwise), `user_id` (customer identifier), `eval_set` (which evaluation this order belongs to), `order_number` (the order number for this user, 1=first, n=nth), `order_dow` (the day of the week when this order was placed), `order_hour_of_day` (the hour of the day when this order was placed), `days_since_prior_order` (days since the last order, capped at 30, NA if order_number=1), `product_name` (name of the product), `aisle_id`(aisle identifier), `department_id` (department identifier), `aisle` (the name of the aisle), `department` (department this product belongs to).

```{r}
n_aisles = instacart |>
  distinct(aisle) |>
  nrow()

aisle_summary = instacart |>
  group_by(aisle) |>
  summarize(n_orders = n()) |>
  arrange(desc(n_orders))

n_aisles
aisle_summary
```
There are 134 aisles on the dataset, and fresh vegetables is the aisle with the most items ordered from.


Plot the number of items ordered in each aisle (>10000 orders)
```{r}
aisle_plot = instacart |>
  group_by(aisle) |>
  summarize(n_orders = n()) |>
  filter(n_orders > 10000) |>
  mutate(aisle = fct_reorder(aisle, n_orders)) 

ggplot(aisle_plot, aes(x = aisle, y = n_orders)) + 
  geom_col(fill = "purple") +
  labs(
    title = "Items ordered by aisle (> 10000 orders)",
    x = "Aisle",
    y = "Number of items ordered") +
  theme_minimal(base_size = 10) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

Table with three most popular items in “baking ingredients”, “dog food care”, and “packaged vegetables fruits”
```{r}
pop_items = instacart |>
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |>
  group_by(aisle, product_name) |>
  summarize(n_orders = n()) |>
  arrange(aisle, desc(n_orders)) |>
  slice_head(n=3)

pop_items
```

Table with mean hour of the day that Pink Lady Apples and Coffee Ice Cream were ordered on each day of the weak
```{r}
meanhour_table = instacart |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  group_by(product_name, order_dow) |>
  summarize(
    mean_hour = mean(order_hour_of_day, na.rm = TRUE)) |>
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour) |>
  knitr::kable(digits = 1)

meanhour_table
```


## Problem 2

Import, clean, and otherwise tidy these datasets.
```{r}
zillow <- read_csv("data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |> 
 janitor::clean_names()

zipcode <- read_csv("data/Zip Codes.csv") |> 
 janitor::clean_names()

zillow_clean <- zillow |> 
  pivot_longer(
    cols = starts_with("x"),
    names_to = "date",
    values_to = "zori"
  ) |>
  mutate(
    date = str_remove(date, "^x"),    
    date = ymd(date),               
    year = year(date),
    month = month(date, label = TRUE, abbr = FALSE),
    zip = as.character(region_name)
  )

zipcode_clean <- zipcode |> 
  select(zip_code, borough = county, neighborhood) |> 
  rename(zip = zip_code) |> 
  mutate(zip = as.character(zip))

zillow_merged <- left_join(zillow_clean, zipcode_clean, by = "zip", relationship = "many-to-many")

zillow_merged <- zillow_merged |>
  select(-state_name) |>
  select(zip, region_id, region_name, region_type, state, city, county_name, borough,
         neighborhood, year, month, date, zori, everything()) |>
  arrange(zip, year, match(month, month.name))

zillow_merged
```

There are 116 months between January 2015 and August 2024. How many ZIP codes are observed 116 times? How many are observed fewer than 10 times? Why are some ZIP codes are observed rarely and others observed in each month?
```{r}
zip_summary <- zillow_merged |>
  filter(!is.na(zori)) |>
  group_by(zip) |>
  summarize(n_months = n_distinct(date))

zip_116 <- zip_summary |>
  summarize(n = sum(n_months == 116))
zip_116

zip_10 <-zip_summary |>
  summarize(n = sum(n_months < 10))
zip_10
```
There are 48 ZIP codes are observed 116 times, and 26 ZIP codes are observed fewer than 10 times. ZIP codes observed in each month might locate at highly populated residential areas (ie. Manhattan) with frequently updated rental markets information; while others are observed rarely might locate at low residential activity area (ie. few rental listings, industrial or commercial zones).


Create a reader-friendly table showing the average rental price in each borough and year (not month). Comment on trends in this table.
```{r}
borough_yr <- zillow_merged |>
  filter(!is.na(zori)) |>
  group_by(borough, year) |>
  summarize(
    mean_zori = mean(zori)) |>
  pivot_wider(
    names_from = year,
    values_from = mean_zori)

borough_yr
```
Manhattan (New York County) has the highest price every year with a wide margin. There’s a huge decrease during 2020–2021 followed by a sharp rebound and new highs by 2023–2024.   
Brooklyn (Kings) and Queens sit in the middle tier with steady increases through 2024. 
The Bronx is consistently the lowest-price borough, but it still shows a clear upward trend over the decade. 
Richmond (Staten Island) has missing early years, but from 2020 to 2024, it shows a steady increase, consistent with post-pandemic recovery. 
Overall trend across boroughs is slight growth pre-COVID, a decrease in 2020–2021, and strong acceleration by 2022–2024, with Manhattan leading and Bronx lowest throughout.














